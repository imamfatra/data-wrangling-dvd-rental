{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9a83a155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, json\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54124c0",
   "metadata": {},
   "source": [
    "# Load and extract Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffb711f",
   "metadata": {},
   "source": [
    "## Data source I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "00405f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_id</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Corua (La Corua)</td>\n",
       "      <td>Spain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Abha</td>\n",
       "      <td>Saudi Arabia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Abu Dhabi</td>\n",
       "      <td>United Arab Emirates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Acua</td>\n",
       "      <td>Mexico</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Adana</td>\n",
       "      <td>Turkey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   city_id                city               country\n",
       "0        1  A Corua (La Corua)                 Spain\n",
       "1        2                Abha          Saudi Arabia\n",
       "2        3           Abu Dhabi  United Arab Emirates\n",
       "3        4                Acua                Mexico\n",
       "4        5               Adana                Turkey"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "\n",
    "source_I_url = \"https://raw.githubusercontent.com/rahilpacmann/case-data-wrangling-api/main/city.csv\"\n",
    "\n",
    "with urllib.request.urlopen(source_I_url) as response:\n",
    "    df_1 = pd.read_csv(response)\n",
    "df_1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283171e2",
   "metadata": {},
   "source": [
    "## Data source II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f6b006d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>last_update</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2006-02-15 09:44:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>2006-02-15 09:44:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American Samoa</td>\n",
       "      <td>2006-02-15 09:44:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>2006-02-15 09:44:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anguilla</td>\n",
       "      <td>2006-02-15 09:44:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country          last_update\n",
       "0     Afghanistan  2006-02-15 09:44:00\n",
       "1         Algeria  2006-02-15 09:44:00\n",
       "2  American Samoa  2006-02-15 09:44:00\n",
       "3          Angola  2006-02-15 09:44:00\n",
       "4        Anguilla  2006-02-15 09:44:00"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_II_url = \"https://raw.githubusercontent.com/rahilpacmann/case-data-wrangling-api/main/country.csv\"\n",
    "\n",
    "with urllib.request.urlopen(source_II_url) as response:\n",
    "    df_2 = pd.read_csv(response)\n",
    "df_2.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2ad126",
   "metadata": {},
   "source": [
    "## Data source III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5a79e649",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, Engine\n",
    "from pandas import DataFrame\n",
    "\n",
    "def source_postgres_engine(database_name: str):\n",
    "    # connection to database\n",
    "    user = \"postgres\"\n",
    "    password = \"qwerty123\"\n",
    "    host = \"localhost\"\n",
    "    port = \"5433\"\n",
    "\n",
    "    engine = create_engine(f\"postgresql://{user}:{password}@{host}:{port}/{database_name}\")\n",
    "    \n",
    "    return engine\n",
    "\n",
    "def get_table_data(table_name: str, engine: Engine) -> DataFrame:\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    return pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "97befead",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = source_postgres_engine(\"dvdrental\")\n",
    "\n",
    "actor_df = get_table_data(\"actor\", engine)\n",
    "store_df = get_table_data('store', engine)\n",
    "address_df = get_table_data('address', engine)\n",
    "category_df = get_table_data('category', engine)\n",
    "customer_df = get_table_data('customer', engine)\n",
    "film_actor_df = get_table_data('film_actor', engine)\n",
    "film_category_df = get_table_data('film_category', engine)\n",
    "inventory_df = get_table_data('inventory',engine)\n",
    "language_df = get_table_data('language',engine)\n",
    "rental_df = get_table_data('rental',engine)\n",
    "staff_df = get_table_data('staff',engine)\n",
    "payment_df = get_table_data('payment',engine)\n",
    "film_df = get_table_data('film',engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "07f403bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    \"actor\": actor_df,\n",
    "    \"store\": store_df,\n",
    "    \"address\": address_df,\n",
    "    \"category\": category_df,\n",
    "    \"customer\": customer_df,\n",
    "    \"film_actor\": film_actor_df,\n",
    "    \"film_category\": film_category_df,\n",
    "    \"inventory\": inventory_df,\n",
    "    \"language\": language_df,\n",
    "    \"rental\": rental_df,\n",
    "    \"staff\": staff_df,\n",
    "    \"payment\": payment_df,\n",
    "    \"film\": film_df,\n",
    "    \"city\": df_1,\n",
    "    \"country\": df_2    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4e8cc9",
   "metadata": {},
   "source": [
    "# Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0345ef71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'actor': [{'column_name': 'actor_id', 'data_type': 'int64'}, {'column_name': 'last_update', 'data_type': 'datetime64[ns]'}, {'column_name': 'first_name', 'data_type': 'object'}, {'column_name': 'last_name', 'data_type': 'object'}], 'store': [{'column_name': 'store_id', 'data_type': 'int64'}, {'column_name': 'manager_staff_id', 'data_type': 'int64'}, {'column_name': 'address_id', 'data_type': 'int64'}, {'column_name': 'last_update', 'data_type': 'datetime64[ns]'}], 'address': [{'column_name': 'last_update', 'data_type': 'datetime64[ns]'}, {'column_name': 'city_id', 'data_type': 'int64'}, {'column_name': 'address_id', 'data_type': 'int64'}, {'column_name': 'district', 'data_type': 'object'}, {'column_name': 'phone', 'data_type': 'object'}, {'column_name': 'postal_code', 'data_type': 'object'}, {'column_name': 'address', 'data_type': 'object'}, {'column_name': 'address2', 'data_type': 'object'}], 'category': [{'column_name': 'category_id', 'data_type': 'int64'}, {'column_name': 'last_update', 'data_type': 'datetime64[ns]'}, {'column_name': 'name', 'data_type': 'object'}], 'city': [{'column_name': 'city_id', 'data_type': 'int64'}, {'column_name': 'country_id', 'data_type': 'int64'}, {'column_name': 'last_update', 'data_type': 'datetime64[ns]'}, {'column_name': 'city', 'data_type': 'object'}], 'country': [{'column_name': 'country_id', 'data_type': 'int64'}, {'column_name': 'last_update', 'data_type': 'datetime64[ns]'}, {'column_name': 'country', 'data_type': 'object'}], 'customer': [{'column_name': 'active', 'data_type': 'int64'}, {'column_name': 'store_id', 'data_type': 'int64'}, {'column_name': 'create_date', 'data_type': 'datetime64[ns]'}, {'column_name': 'last_update', 'data_type': 'datetime64[ns]'}, {'column_name': 'customer_id', 'data_type': 'int64'}, {'column_name': 'address_id', 'data_type': 'int64'}, {'column_name': 'activebool', 'data_type': 'bool'}, {'column_name': 'first_name', 'data_type': 'object'}, {'column_name': 'last_name', 'data_type': 'object'}, {'column_name': 'email', 'data_type': 'object'}], 'film_actor': [{'column_name': 'actor_id', 'data_type': 'int64'}, {'column_name': 'film_id', 'data_type': 'int64'}, {'column_name': 'last_update', 'data_type': 'datetime64[ns]'}], 'film_category': [{'column_name': 'film_id', 'data_type': 'int64'}, {'column_name': 'category_id', 'data_type': 'int64'}, {'column_name': 'last_update', 'data_type': 'datetime64[ns]'}], 'inventory': [{'column_name': 'inventory_id', 'data_type': 'int64'}, {'column_name': 'film_id', 'data_type': 'int64'}, {'column_name': 'store_id', 'data_type': 'int64'}, {'column_name': 'last_update', 'data_type': 'datetime64[ns]'}], 'language': [{'column_name': 'language_id', 'data_type': 'int64'}, {'column_name': 'last_update', 'data_type': 'datetime64[ns]'}, {'column_name': 'name', 'data_type': 'object'}], 'rental': [{'column_name': 'rental_id', 'data_type': 'int64'}, {'column_name': 'rental_date', 'data_type': 'datetime64[ns]'}, {'column_name': 'inventory_id', 'data_type': 'int64'}, {'column_name': 'customer_id', 'data_type': 'int64'}, {'column_name': 'return_date', 'data_type': 'datetime64[ns]'}, {'column_name': 'staff_id', 'data_type': 'int64'}, {'column_name': 'last_update', 'data_type': 'datetime64[ns]'}], 'staff': [{'column_name': 'picture', 'data_type': 'object'}, {'column_name': 'address_id', 'data_type': 'int64'}, {'column_name': 'store_id', 'data_type': 'int64'}, {'column_name': 'active', 'data_type': 'bool'}, {'column_name': 'last_update', 'data_type': 'datetime64[ns]'}, {'column_name': 'staff_id', 'data_type': 'int64'}, {'column_name': 'first_name', 'data_type': 'object'}, {'column_name': 'last_name', 'data_type': 'object'}, {'column_name': 'password', 'data_type': 'object'}, {'column_name': 'email', 'data_type': 'object'}, {'column_name': 'username', 'data_type': 'object'}], 'payment': [{'column_name': 'payment_id', 'data_type': 'int64'}, {'column_name': 'customer_id', 'data_type': 'int64'}, {'column_name': 'staff_id', 'data_type': 'int64'}, {'column_name': 'rental_id', 'data_type': 'int64'}, {'column_name': 'amount', 'data_type': 'float64'}, {'column_name': 'payment_date', 'data_type': 'datetime64[ns]'}], 'film': [{'column_name': 'fulltext', 'data_type': 'object'}, {'column_name': 'rating', 'data_type': 'object'}, {'column_name': 'last_update', 'data_type': 'datetime64[ns]'}, {'column_name': 'film_id', 'data_type': 'int64'}, {'column_name': 'release_year', 'data_type': 'int64'}, {'column_name': 'language_id', 'data_type': 'int64'}, {'column_name': 'rental_duration', 'data_type': 'int64'}, {'column_name': 'rental_rate', 'data_type': 'float64'}, {'column_name': 'length', 'data_type': 'int64'}, {'column_name': 'replacement_cost', 'data_type': 'float64'}, {'column_name': 'title', 'data_type': 'object'}, {'column_name': 'description', 'data_type': 'object'}, {'column_name': 'special_features', 'data_type': 'object'}]}\n"
     ]
    }
   ],
   "source": [
    "requirement_url = \"https://rahilpacmann.github.io/case-data-wrangling-api/requirements_table.json\"\n",
    "\n",
    "with urllib.request.urlopen(requirement_url) as response:\n",
    "    requirement_json = json.load(response)\n",
    "print(requirement_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ba3c91a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['actor', 'store', 'address', 'category', 'city', 'country', 'customer', 'film_actor', 'film_category', 'inventory', 'language', 'rental', 'staff', 'payment', 'film']\n"
     ]
    }
   ],
   "source": [
    "actual_table_name = list(requirement_json.keys())\n",
    "print(actual_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f0cb57c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> STEP 1: CHECK TABLE\n",
      "+---------------+------------+\n",
      "| Table name    | Is exist   |\n",
      "+===============+============+\n",
      "| actor         | ✓          |\n",
      "+---------------+------------+\n",
      "| store         | ✓          |\n",
      "+---------------+------------+\n",
      "| address       | ✓          |\n",
      "+---------------+------------+\n",
      "| category      | ✓          |\n",
      "+---------------+------------+\n",
      "| city          | ✓          |\n",
      "+---------------+------------+\n",
      "| country       | ✓          |\n",
      "+---------------+------------+\n",
      "| customer      | ✓          |\n",
      "+---------------+------------+\n",
      "| film_actor    | ✓          |\n",
      "+---------------+------------+\n",
      "| film_category | ✓          |\n",
      "+---------------+------------+\n",
      "| inventory     | ✓          |\n",
      "+---------------+------------+\n",
      "| language      | ✓          |\n",
      "+---------------+------------+\n",
      "| rental        | ✓          |\n",
      "+---------------+------------+\n",
      "| staff         | ✓          |\n",
      "+---------------+------------+\n",
      "| payment       | ✓          |\n",
      "+---------------+------------+\n",
      "| film          | ✓          |\n",
      "+---------------+------------+\n"
     ]
    }
   ],
   "source": [
    "def check_table_requirements(actual_table: dict, requirement_table: dict):\n",
    "    actual_table_name = list(actual_table.keys())\n",
    "    requirement_table_name = list(requirement_table.keys())\n",
    "\n",
    "    table_checking = []\n",
    "    for table_name in requirement_table_name:\n",
    "        if table_name in actual_table_name:\n",
    "            table_checking.append([table_name, \"✓\"])\n",
    "        else:\n",
    "            table_checking.append([table_name, \"✗\"])\n",
    "    \n",
    "    table_headers = [\"Table name\", \"Is exist\"]\n",
    "    table = tabulate(table_checking, headers=table_headers, tablefmt=\"grid\")\n",
    "    print(\"=> STEP 1: CHECK TABLE\")\n",
    "    print(table)\n",
    "\n",
    "check_table_requirements(data_dict, requirement_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "61d3ab15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> STEP 2: CHECK TABLE SHAPE\n",
      "+---------------+------------------+---------------------+\n",
      "| Table name    |   Number of rows |   Number of columns |\n",
      "+===============+==================+=====================+\n",
      "| actor         |              200 |                   4 |\n",
      "+---------------+------------------+---------------------+\n",
      "| store         |                2 |                   4 |\n",
      "+---------------+------------------+---------------------+\n",
      "| address       |              603 |                   8 |\n",
      "+---------------+------------------+---------------------+\n",
      "| category      |               16 |                   3 |\n",
      "+---------------+------------------+---------------------+\n",
      "| customer      |              599 |                  10 |\n",
      "+---------------+------------------+---------------------+\n",
      "| film_actor    |             5462 |                   3 |\n",
      "+---------------+------------------+---------------------+\n",
      "| film_category |             1000 |                   3 |\n",
      "+---------------+------------------+---------------------+\n",
      "| inventory     |             4581 |                   4 |\n",
      "+---------------+------------------+---------------------+\n",
      "| language      |                6 |                   3 |\n",
      "+---------------+------------------+---------------------+\n",
      "| rental        |            16044 |                   7 |\n",
      "+---------------+------------------+---------------------+\n",
      "| staff         |                2 |                  11 |\n",
      "+---------------+------------------+---------------------+\n",
      "| payment       |            14596 |                   6 |\n",
      "+---------------+------------------+---------------------+\n",
      "| film          |             1000 |                  13 |\n",
      "+---------------+------------------+---------------------+\n",
      "| city          |              677 |                   3 |\n",
      "+---------------+------------------+---------------------+\n",
      "| country       |              109 |                   2 |\n",
      "+---------------+------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "def check_data_shape(actual_table: dict):\n",
    "    table_shape = []\n",
    "\n",
    "    for table_name in actual_table:\n",
    "        rows, cols = actual_table[table_name].shape\n",
    "        table_shape.append([table_name, rows, cols])\n",
    "    \n",
    "    table_headers = [\"Table name\", \"Number of rows\", \"Number of columns\"]\n",
    "    table = tabulate(table_shape, headers=table_headers, tablefmt=\"grid\")\n",
    "    print(\"=> STEP 2: CHECK TABLE SHAPE\")\n",
    "    print(table)\n",
    "    \n",
    "check_data_shape(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4af8e208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> STEP 3: CHECK COLUMNS\n",
      "city\n",
      "+---------------+-------------------+------------------------+\n",
      "| Column name   | In actual table   | In requirement table   |\n",
      "+===============+===================+========================+\n",
      "| city_id       | ✔                 | ✔                      |\n",
      "+---------------+-------------------+------------------------+\n",
      "| country       | ✔                 | ✘                      |\n",
      "+---------------+-------------------+------------------------+\n",
      "| last_update   | ✘                 | ✔                      |\n",
      "+---------------+-------------------+------------------------+\n",
      "| country_id    | ✘                 | ✔                      |\n",
      "+---------------+-------------------+------------------------+\n",
      "| city          | ✔                 | ✔                      |\n",
      "+---------------+-------------------+------------------------+\n",
      "\n",
      "\n",
      "country\n",
      "+---------------+-------------------+------------------------+\n",
      "| Column name   | In actual table   | In requirement table   |\n",
      "+===============+===================+========================+\n",
      "| country       | ✔                 | ✔                      |\n",
      "+---------------+-------------------+------------------------+\n",
      "| country_id    | ✘                 | ✔                      |\n",
      "+---------------+-------------------+------------------------+\n",
      "| last_update   | ✔                 | ✔                      |\n",
      "+---------------+-------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def check_columns(actual_table: dict, requirement_table: dict):\n",
    "    print(\"=> STEP 3: CHECK COLUMNS\")\n",
    "\n",
    "    for table_name in requirement_table:\n",
    "        result = []\n",
    "        actual_columns = list(actual_table[table_name].columns)\n",
    "        requirement_columns = []\n",
    "\n",
    "        for data in requirement_table[table_name]:\n",
    "            requirement_columns.append(data[\"column_name\"])\n",
    "        \n",
    "        for column_name in set(actual_columns + requirement_columns):\n",
    "            in_actual_table = \"✔\" if column_name in actual_columns else \"✘\"\n",
    "            in_requirement_table = \"✔\" if column_name in requirement_columns else \"✘\"\n",
    "            result.append([column_name, in_actual_table, in_requirement_table])\n",
    "\n",
    "        if set(actual_columns) == set(requirement_columns):\n",
    "            pass\n",
    "        else:\n",
    "            print(table_name)\n",
    "            table_headers = [\"Column name\", \"In actual table\", \"In requirement table\"]\n",
    "            table = tabulate(result, headers=table_headers, tablefmt=\"grid\")\n",
    "            print(table)\n",
    "            print(\"\\n\")\n",
    "            \n",
    "check_columns(data_dict, requirement_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "24a2599c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> STEP 4: CHECK DATA TYPE\n",
      "\n",
      "Summary of Mismatches Data Types:\n",
      "+--------------+---------------+---------------+--------------------+----------------------+\n",
      "| Table name   | Column name   | Actual type   | Requirement type   | Match                |\n",
      "+==============+===============+===============+====================+======================+\n",
      "| customer     | create_date   | object        | datetime64[ns]     | ✘                    |\n",
      "+--------------+---------------+---------------+--------------------+----------------------+\n",
      "| city         | country_id    | N/A           | int64              | ✘ (Column not found) |\n",
      "+--------------+---------------+---------------+--------------------+----------------------+\n",
      "| city         | last_update   | N/A           | datetime64[ns]     | ✘ (Column not found) |\n",
      "+--------------+---------------+---------------+--------------------+----------------------+\n",
      "| country      | country_id    | N/A           | int64              | ✘ (Column not found) |\n",
      "+--------------+---------------+---------------+--------------------+----------------------+\n",
      "| country      | last_update   | object        | datetime64[ns]     | ✘                    |\n",
      "+--------------+---------------+---------------+--------------------+----------------------+\n"
     ]
    }
   ],
   "source": [
    "def check_data_type(actual_table: dict, requirement_table: dict):\n",
    "    result = []\n",
    "\n",
    "    for table_name, df in actual_table.items():\n",
    "        if table_name in requirement_table:\n",
    "            for info_table in requirement_table[table_name]:\n",
    "                column_name = info_table[\"column_name\"] \n",
    "                data_type_req = info_table[\"data_type\"]\n",
    "                if column_name in df.columns:\n",
    "                    data_type_actual = df[column_name].dtype\n",
    "                    result_data_type = \"✔\" if data_type_req == data_type_actual else \"✘\"\n",
    "                    result.append([table_name, column_name, data_type_actual, \n",
    "                                   data_type_req, result_data_type])\n",
    "                else:\n",
    "                    result.append([table_name, column_name, \"N/A\", \n",
    "                                   data_type_req, \"✘ (Column not found)\"])\n",
    "    \n",
    "    print(\"=> STEP 4: CHECK DATA TYPE\")\n",
    "    table_headers = [\"Table name\", \"Column name\", \"Actual type\", \"Requirement type\", \"Match\"]\n",
    "    \n",
    "    missmatch_data = [row for row in result if \"✘\" in row[4]] \n",
    "    if missmatch_data:\n",
    "        print(\"\\nSummary of Mismatches Data Types:\")\n",
    "        table = tabulate(missmatch_data, headers=table_headers, tablefmt=\"grid\")\n",
    "        print(table)\n",
    "    else:\n",
    "        print(\"All data types match\")\n",
    "\n",
    "check_data_type(data_dict, requirement_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "046800d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> STEP 5: CHECK MISSING VALUE\n",
      "+--------------+---------------+-----------------------+----------------------------+\n",
      "| Table name   | Column name   |   Missing value count |   Missing value percentage |\n",
      "+==============+===============+=======================+============================+\n",
      "| address      | address2      |                     4 |                       0.66 |\n",
      "+--------------+---------------+-----------------------+----------------------------+\n",
      "| rental       | return_date   |                   183 |                       1.14 |\n",
      "+--------------+---------------+-----------------------+----------------------------+\n",
      "| staff        | picture       |                     1 |                      50    |\n",
      "+--------------+---------------+-----------------------+----------------------------+\n",
      "| city         | city          |                    10 |                       1.48 |\n",
      "+--------------+---------------+-----------------------+----------------------------+\n",
      "| city         | country       |                     7 |                       1.03 |\n",
      "+--------------+---------------+-----------------------+----------------------------+\n"
     ]
    }
   ],
   "source": [
    "def check_missing_values(actual_table: dict):\n",
    "    result = []\n",
    "\n",
    "    for table_name, df in actual_table.items():\n",
    "        missing_count = df.isna().sum()\n",
    "        total_data = df.shape[0]\n",
    "        \n",
    "        for column, missing in missing_count.items():\n",
    "            missing_count_percantage = round((missing / total_data * 100), 2)\n",
    "            result.append([table_name, column, missing, missing_count_percantage])\n",
    "    \n",
    "    table_headers = [\"Table name\", \"Column name\", \"Missing value count\", \n",
    "                     \"Missing value percentage\"]\n",
    "    missing_value = [row for row in result if row[2] != 0]\n",
    "    if missing_value:\n",
    "        table = tabulate(missing_value, headers=table_headers, tablefmt=\"grid\")\n",
    "        print(\"=> STEP 5: CHECK MISSING VALUE\")\n",
    "        print(table)\n",
    "    else:\n",
    "        print(\"There's no Missing Values\")\n",
    "\n",
    "check_missing_values(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "71861171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> STEP 6: CHECK DUPLICATES DATA\n",
      "Duplicate Data Summary:\n",
      "+--------------+------------------------+\n",
      "| Table name   |   Duplicate rows count |\n",
      "+==============+========================+\n",
      "| city         |                    154 |\n",
      "+--------------+------------------------+\n"
     ]
    }
   ],
   "source": [
    "def check_duplicates_data(actual_table: dict):\n",
    "    result = []\n",
    "\n",
    "    for table_name, df in actual_table.items():\n",
    "        # duplicate_rows = df[df.duplicated(keep=False)]\n",
    "        duplicate_rows = df.astype(str).duplicated(keep=False).sum()\n",
    "        result.append([table_name, duplicate_rows])\n",
    "    \n",
    "    duplicate_data = [row for row in result if row[1] != 0]\n",
    "    if duplicate_data:\n",
    "        table_headers = [\"Table name\", \"Duplicate rows count\"]\n",
    "        duplicates_data = [row for row in result if row[1] != 0]\n",
    "        table = tabulate(duplicates_data, headers=table_headers, tablefmt=\"grid\")\n",
    "        print(\"=> STEP 6: CHECK DUPLICATES DATA\")\n",
    "        print(\"Duplicate Data Summary:\")\n",
    "        print(table)\n",
    "    else:   \n",
    "        print(\"No Duplicate Data Found\")\n",
    "\n",
    "check_duplicates_data(data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93b108d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f4cdc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
